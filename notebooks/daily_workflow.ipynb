{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364faff8",
   "metadata": {},
   "source": [
    "# Daily Macro Signal Research Workflow\n",
    "Complete pipeline from data ingestion to model training and backtesting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1a52a2",
   "metadata": {},
   "source": [
    "## 1. Setup and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22610d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (Kaggle environment)\n",
    "!pip install prisma-client-python torch transformers optuna nixtla==0.2.8 fredapi yfinance pandas_datareader psycopg2-binary ta quantlib google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb3a47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Import project modules\n",
    "from src.db.client import get_db, health_check\n",
    "from src.data_ingest.fred import ingest_fred_data\n",
    "from src.data_ingest.yahoo import ingest_yahoo_data\n",
    "from src.timejoin.spine import create_feature_spine\n",
    "from src.features.tech import create_feature_matrix\n",
    "from src.models.patchtst import PatchTSTWrapper, finetune_patchtst\n",
    "\n",
    "print(\"‚úÖ Environment setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7425f239",
   "metadata": {},
   "source": [
    "## 2. Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c930727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set database connection\n",
    "# In Kaggle, add these as secrets:\n",
    "# DATABASE_URL, FRED_API_KEY, GEMINI_API_KEY\n",
    "\n",
    "os.environ['DATABASE_URL'] = 'YOUR_POSTGRES_CONNECTION_STRING'\n",
    "os.environ['FRED_API_KEY'] = 'YOUR_FRED_API_KEY'\n",
    "os.environ['GEMINI_API_KEY'] = 'YOUR_GEMINI_API_KEY'\n",
    "\n",
    "# Test database connection\n",
    "health = await health_check()\n",
    "print(f\"Database health: {health['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371dd97a",
   "metadata": {},
   "source": [
    "## 3. Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145a31a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest macro economic data from FRED\n",
    "print(\"üìä Ingesting macro data...\")\n",
    "fred_count = await ingest_fred_data(os.getenv('FRED_API_KEY'))\n",
    "print(f\"Ingested {fred_count} macro release records\")\n",
    "\n",
    "# Ingest market data from Yahoo Finance\n",
    "print(\"üìà Ingesting market data...\")\n",
    "market_count = await ingest_yahoo_data(\n",
    "    tickers=['SPY', 'EURUSD=X', 'GLD', 'TLT'],\n",
    "    start_date='2020-01-01',\n",
    "    end_date='2024-12-31'\n",
    ")\n",
    "print(f\"Ingested {market_count} market price records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1ec59d",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d40cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature spine with as-of joined macro data\n",
    "print(\"üîß Building feature spine...\")\n",
    "ticker = 'SPY'\n",
    "feature_spine = await create_feature_spine(\n",
    "    ticker=ticker,\n",
    "    start_date='2021-01-01',\n",
    "    end_date='2024-12-31',\n",
    "    include_macro=True\n",
    ")\n",
    "\n",
    "print(f\"Feature spine shape: {feature_spine.shape}\")\n",
    "print(f\"Date range: {feature_spine['ts'].min()} to {feature_spine['ts'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29191bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive technical features\n",
    "print(\"üéØ Generating technical features...\")\n",
    "feature_matrix = create_feature_matrix(\n",
    "    feature_spine,\n",
    "    include_technical=True,\n",
    "    include_macro=True,\n",
    "    dropna=True\n",
    ")\n",
    "\n",
    "print(f\"Feature matrix shape: {feature_matrix.shape}\")\n",
    "print(f\"Features: {[col for col in feature_matrix.columns if col not in ['ts', 'ticker', 'open', 'high', 'low', 'close', 'volume']][:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9453312f",
   "metadata": {},
   "source": [
    "## 5. Model Training - PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7025a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for PatchTST\n",
    "model = PatchTSTWrapper(\n",
    "    context_length=256,\n",
    "    prediction_length=30,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Use close price as target\n",
    "X, y = model.prepare_data(feature_matrix, target_col='close')\n",
    "print(f\"Prepared data: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "# Split into train/validation\n",
    "split_idx = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"Train: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Validation: X={X_val.shape}, y={y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0299b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train PatchTST model\n",
    "print(\"üöÄ Training PatchTST model...\")\n",
    "model, metrics = finetune_patchtst(\n",
    "    X_train, y_train, X_val, y_val,\n",
    "    gpu=True,\n",
    "    epochs=25,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Training completed!\")\n",
    "print(f\"Final train loss: {metrics['final_train_loss']:.6f}\")\n",
    "print(f\"Final validation loss: {metrics['final_val_loss']:.6f}\")\n",
    "print(f\"Best validation loss: {metrics['best_val_loss']:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4315bb85",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510a474b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "predictions = model.predict(X_val)\n",
    "print(f\"Generated {len(predictions)} predictions\")\n",
    "\n",
    "# Plot training losses\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(metrics['train_losses'], label='Train Loss')\n",
    "plt.plot(metrics['val_losses'], label='Validation Loss')\n",
    "plt.title('Training Progress')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Plot sample predictions vs actual\n",
    "sample_idx = 0\n",
    "plt.plot(y_val[sample_idx], label='Actual', alpha=0.7)\n",
    "plt.plot(predictions[sample_idx], label='Predicted', alpha=0.7)\n",
    "plt.title('Sample Prediction vs Actual')\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dfb71b",
   "metadata": {},
   "source": [
    "## 7. Store Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8778f102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store trained model in database\n",
    "from src.models.patchtst import torch_save_bytes\n",
    "\n",
    "db = await get_db()\n",
    "strategy_id = f'patchtst_{ticker}_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}'\n",
    "\n",
    "model_blob = torch_save_bytes(model)\n",
    "\n",
    "await db.modelartifact.create({\n",
    "    'strategy_id': strategy_id,\n",
    "    'model_type': 'patchtst',\n",
    "    'blob': model_blob,\n",
    "    'metrics_json': metrics,\n",
    "    'config_yaml': f'ticker: {ticker}\\ncontext_length: 256\\nprediction_length: 30'\n",
    "})\n",
    "\n",
    "print(f\"‚úÖ Model stored with strategy_id: {strategy_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341ff41",
   "metadata": {},
   "source": [
    "## 8. TimeGPT Comparison (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3985037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with TimeGPT API\n",
    "try:\n",
    "    from nixtla import TimeGPT\n",
    "    \n",
    "    # Initialize TimeGPT (requires API key)\n",
    "    timegpt = TimeGPT(api_key=os.getenv('TIMEGPT_API_KEY'))\n",
    "    \n",
    "    # Prepare data for TimeGPT (needs specific format)\n",
    "    timegpt_df = feature_matrix[['ts', 'close']].copy()\n",
    "    timegpt_df.columns = ['ds', 'y']\n",
    "    timegpt_df = timegpt_df.tail(500)  # Use recent data\n",
    "    \n",
    "    # Generate forecast\n",
    "    timegpt_forecast = timegpt.forecast(timegpt_df, h=30)\n",
    "    \n",
    "    print(\"üìà TimeGPT forecast generated\")\n",
    "    print(timegpt_forecast.head())\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è TimeGPT not available - skipping comparison\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è TimeGPT error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b495a6d",
   "metadata": {},
   "source": [
    "## 9. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4bf7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export feature matrix and predictions for further analysis\n",
    "feature_matrix.to_csv(f'feature_matrix_{ticker}.csv', index=False)\n",
    "print(f\"‚úÖ Feature matrix exported: feature_matrix_{ticker}.csv\")\n",
    "\n",
    "# Export predictions\n",
    "pred_df = pd.DataFrame({\n",
    "    'prediction_id': range(len(predictions)),\n",
    "    'predictions': [pred.tolist() for pred in predictions],\n",
    "    'actual': [actual.tolist() for actual in y_val]\n",
    "})\n",
    "pred_df.to_json(f'predictions_{ticker}.json', orient='records')\n",
    "print(f\"‚úÖ Predictions exported: predictions_{ticker}.json\")\n",
    "\n",
    "print(\"\\nüéâ Daily workflow completed successfully!\")\n",
    "print(f\"Strategy ID: {strategy_id}\")\n",
    "print(f\"Model performance: {metrics['best_val_loss']:.6f} MSE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11390b1",
   "metadata": {},
   "source": [
    "## 8. Monitoring and Alert Generation üìä\n",
    "\n",
    "Monitor system health, data quality, and model performance. Generate alerts for significant deviations or issues that require attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb926db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Monitoring\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configure monitoring logger\n",
    "monitoring_logger = logging.getLogger('monitoring')\n",
    "monitoring_logger.setLevel(logging.INFO)\n",
    "\n",
    "print(\"üîç Running Data Quality Checks...\")\n",
    "\n",
    "# Check recent data ingestion\n",
    "recent_cutoff = datetime.now() - timedelta(days=7)\n",
    "\n",
    "# Check market data freshness\n",
    "recent_prices = await db.marketprice.count(\n",
    "    where={'created_at': {'gte': recent_cutoff}}\n",
    ")\n",
    "\n",
    "# Check macro data freshness  \n",
    "recent_macro = await db.macrorelease.count(\n",
    "    where={'created_at': {'gte': recent_cutoff}}\n",
    ")\n",
    "\n",
    "# Check features freshness\n",
    "recent_features = await db.feature.count(\n",
    "    where={'created_at': {'gte': recent_cutoff}}\n",
    ")\n",
    "\n",
    "print(f\"üìà Recent Price Records: {recent_prices:,}\")\n",
    "print(f\"üèõÔ∏è Recent Macro Records: {recent_macro:,}\")\n",
    "print(f\"‚öôÔ∏è Recent Feature Records: {recent_features:,}\")\n",
    "\n",
    "# Quality thresholds\n",
    "alerts = []\n",
    "if recent_prices < 100:\n",
    "    alerts.append(\"‚ö†Ô∏è LOW PRICE DATA: Fewer than 100 records in past week\")\n",
    "if recent_macro < 10:\n",
    "    alerts.append(\"‚ö†Ô∏è LOW MACRO DATA: Fewer than 10 releases in past week\")\n",
    "if recent_features < 1000:\n",
    "    alerts.append(\"‚ö†Ô∏è LOW FEATURE DATA: Fewer than 1000 features in past week\")\n",
    "\n",
    "if alerts:\n",
    "    print(\"\\nüö® DATA QUALITY ALERTS:\")\n",
    "    for alert in alerts:\n",
    "        print(f\"  {alert}\")\n",
    "else:\n",
    "    print(\"‚úÖ All data quality checks passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f5d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Performance Monitoring\n",
    "print(\"\\nü§ñ Checking Model Performance...\")\n",
    "\n",
    "# Get recent backtest results\n",
    "recent_backtests = await db.backtestresult.find_many(\n",
    "    where={'created_at': {'gte': recent_cutoff}},\n",
    "    order_by={'created_at': 'desc'},\n",
    "    take=10\n",
    ")\n",
    "\n",
    "if recent_backtests:\n",
    "    # Calculate performance metrics\n",
    "    sharpe_ratios = [bt.sharpe_ratio for bt in recent_backtests]\n",
    "    total_returns = [bt.total_return for bt in recent_backtests]\n",
    "    max_drawdowns = [bt.max_drawdown for bt in recent_backtests]\n",
    "    \n",
    "    avg_sharpe = np.mean(sharpe_ratios)\n",
    "    avg_return = np.mean(total_returns)\n",
    "    worst_drawdown = min(max_drawdowns)\n",
    "    \n",
    "    print(f\"üìä Recent Performance (last {len(recent_backtests)} backtests):\")\n",
    "    print(f\"  Average Sharpe Ratio: {avg_sharpe:.3f}\")\n",
    "    print(f\"  Average Return: {avg_return:.2%}\")\n",
    "    print(f\"  Worst Drawdown: {worst_drawdown:.2%}\")\n",
    "    \n",
    "    # Performance alerts\n",
    "    performance_alerts = []\n",
    "    if avg_sharpe < 0.5:\n",
    "        performance_alerts.append(\"‚ö†Ô∏è LOW SHARPE: Average Sharpe ratio below 0.5\")\n",
    "    if avg_return < -0.05:\n",
    "        performance_alerts.append(\"‚ö†Ô∏è NEGATIVE RETURNS: Average return below -5%\")\n",
    "    if worst_drawdown < -0.20:\n",
    "        performance_alerts.append(\"‚ö†Ô∏è HIGH DRAWDOWN: Drawdown exceeding -20%\")\n",
    "        \n",
    "    if performance_alerts:\n",
    "        print(\"\\nüö® PERFORMANCE ALERTS:\")\n",
    "        for alert in performance_alerts:\n",
    "            print(f\"  {alert}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Model performance within acceptable ranges\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No recent backtest results found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d3fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Health and Final Report\n",
    "print(\"\\nüè• System Health Check...\")\n",
    "\n",
    "# Check database connections and table sizes\n",
    "try:\n",
    "    table_counts = {\n",
    "        'MarketPrice': await db.marketprice.count(),\n",
    "        'MacroRelease': await db.macrorelease.count(),\n",
    "        'Feature': await db.feature.count(),\n",
    "        'Signal': await db.signal.count(),\n",
    "        'Strategy': await db.strategy.count()\n",
    "    }\n",
    "    \n",
    "    print(\"üìä Database Table Counts:\")\n",
    "    for table, count in table_counts.items():\n",
    "        print(f\"  {table}: {count:,} records\")\n",
    "    \n",
    "    # Storage usage estimation (simplified)\n",
    "    total_records = sum(table_counts.values())\n",
    "    estimated_storage_mb = total_records * 0.001  # ~1KB per record\n",
    "    \n",
    "    print(f\"\\nüíæ Estimated Storage: {estimated_storage_mb:.1f} MB\")\n",
    "    \n",
    "    if estimated_storage_mb > 10000:  # 10GB threshold\n",
    "        print(\"‚ö†Ô∏è Storage usage exceeding 10GB - consider archiving old data\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Database health check failed: {e}\")\n",
    "\n",
    "# Workflow Summary\n",
    "end_time = datetime.now()\n",
    "total_duration = end_time - start_time\n",
    "\n",
    "print(f\"\\nüéØ DAILY WORKFLOW SUMMARY\")\n",
    "print(f\"=\" * 50)\n",
    "print(f\"‚è±Ô∏è Total Runtime: {total_duration}\")\n",
    "print(f\"üìÖ Completed: {end_time.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üéØ Strategy ID: {STRATEGY_ID}\")\n",
    "print(f\"üìä Models Trained: {len(model_results) if 'model_results' in locals() else 0}\")\n",
    "print(f\"üîÑ Backtests Run: {len(recent_backtests) if recent_backtests else 0}\")\n",
    "print(f\"üö® Alerts Generated: {len(alerts + performance_alerts) if alerts else 0}\")\n",
    "\n",
    "if total_duration.total_seconds() < 3600:  # Under 1 hour\n",
    "    print(\"‚úÖ Workflow completed within performance target!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Workflow exceeded 1-hour target - consider optimization\")\n",
    "\n",
    "print(f\"\\nüöÄ Daily workflow complete! Ready for Kaggle export.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
